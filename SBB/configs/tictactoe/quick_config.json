# This file has a sample configuration for a very quick training of tictactoe players.
# The goal is just to see if everything is working, to train actual good players
# check the other configuration files.

# Sample result:
#   ### Summary Per Run
#   
#   Global Mean Fitness Score per Training per Run:
#   [0.329]
#   mean: 0.329
#   
#   Global Max. Fitness Score per Training per Run:
#   [0.4]
#   mean: 0.4
#   
#   Global Mean Validation Score per Validation per Run:
#   [0.36]
#   mean: 0.36
#   
#   Global Max. Validation Score per Validation per Run:
#   [0.3875]
#   mean: 0.3875
#   
#   Champion Score per Validation per Run:
#   [0.33125]
#   mean: 0.33125
#   
#   Finished execution, total elapsed time: 0.03436 mins (mean: 0.03436, std: 0.0)

{
    "task": "reinforcement", 

    "reinforcement_parameters": { # only used if "task" is "reinforcement"
        "environment": "tictactoe",
        "validation_population": 20, # at a validated generation, all the teams with be tested against this population, the best one is the champion
        "champion_population": 40, # at a validated generation, these are the points the champion team will play against to obtain the metrics
        "hall_of_fame": {
            "enabled": false, 
            "size": 20,
            "opponents": 0, # set to 0 if you want a hall of fame, but not as opponents
            "diversity": "genotype" # if None, use the fitness as the criteria to remove teams when the Hall of Fame is full
        }, 
        "environment_parameters": {
            "actions_total": 9, # for tictactoe: spaces in the board
            "weights_per_action": [], # used by diversities 'hamming' and 'euclidean', only relevant if different actions have different weights
            "inputs_total": 9, # for tictactoe: spaces in the board
            "point_labels_total": 1, # for tictactoe: since no labels are being used
            "training_opponents_labels": ["random", "smart"], # if there are no opponents, set as None or []
            "validation_opponents_labels": ["random", "smart"] # if there are no opponents, set as None or []
        }
    },

    "training_parameters": {
        "runs_total": 1,
        "generations_total": 20, 
        "validate_after_each_generation": 20,
        "populations": {
            "points": 10, 
            "teams": 10
        }, 
        "team_size": {
            "max": 9, 
            "min": 2 
        }, 
        "program_size": {
            "max": 20, 
            "min": 2
        }, 
        "mutation": {
            "program": {
                "change_action": 0.1, 
                "change_instruction": 1.0, 
                "add_instruction": 0.5, 
                "swap_instructions": 1.0, 
                "remove_instruction": 0.5
            }, 
            "team": {
                "add_program": 0.7, 
                "mutate_program": 0.2, 
                "remove_program": 0.7
            }
        }, 
        "replacement_rate": {
            "points": 0.2, 
            "teams": 0.5
        }
    }, 
    
    "advanced_training_parameters": {
        "seed": 1, # use None for a random seed (obs.: it doesn"t guarantee that the same seeds lead to the same runs)
        "use_operations": [
            "+", "-", "*", "/", 
            "ln", "exp", "cos", 
            "if_lesser_than", 
            "if_equal_or_higher_than"
        ], 
        "extra_registers": 4, 
        "diversity": {
            "k": 10, 
            "metrics": [
                "genotype"
            ]
        }, 
        "novelty": {
            "enabled": false,
            "use_fitness": true
        },
        "use_weighted_probability_selection": false, # if False, uniform probability will be used
        "use_agressive_mutations": true, 
        "second_layer": {
            "path": "actions_reference/actions.json", 
            "enabled": false
        }
    },

    "debug": {
        "enabled": false,
        "output_path": "logs/"
    },

    "verbose": {
        "dont_show_std_deviation_in_reports": true
    }
}