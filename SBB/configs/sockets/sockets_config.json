# This file has a sample configuration for a training of tictactoe players via sockets
# To execute the client socket, run 'python SBB\tests\system_tests\tictactoe_game.py' on the root folder

# This file contains only configurations for reinforcement learning (with sockets).

# Sample result:
#   Global Mean Validation Score per Validation per Run: [0.46409]
#   Champion Score per Validation per Run (champion): [0.57562]
#   Runtime: 42 mins

{
    "task": "reinforcement", 

    "reinforcement_parameters": { # only used if "task" is "reinforcement"
        "environment": "sockets",
        "validation_population": 200, # at a validated generation, all the teams with be tested against this population, the best one is the champion
        "champion_population": 400, # at a validated generation, these are the points the champion team will play against to obtain the metrics
        "hall_of_fame": {
            "enabled": false, 
            "size": 20,
            "opponents": 0, # set to 0 if you want a hall of fame, but not as opponents
            "diversity": "genotype" # if None, use the fitness as the criteria to remove teams when the Hall of Fame is full
        }, 
        "environment_parameters": {
            "actions_total": 9, # for tictactoe: spaces in the board
            "weights_per_action": [], # used by diversities 'hamming' and 'euclidean', only relevant if different actions have different weights
            "inputs_total": 9, # for tictactoe: spaces in the board
            "point_labels_total": 1, # for tictactoe: since no labels are being used
            "training_opponents_labels": ["random", "smart"], # if there are no opponents, set as None or []
            "validation_opponents_labels": ["random", "smart"] # if there are no opponents, set as None or []
        },
        "sockets_parameters": { # only used if "environment" is "sockets"
            "connection": {
                "host": "localhost",
                "port": 7800,
                "timeout": 120,
                "buffer": 5000
            }
        }
    },

    "training_parameters": {
        "runs_total": 1,
        "generations_total": 100, 
        "validate_after_each_generation": 25,
        "populations": {
            "points": 100, 
            "teams": 100
        }, 
        "team_size": {
            "max": 12, 
            "min": 2 
        }, 
        "program_size": {
            "max": 20, 
            "min": 5
        }, 
        "mutation": {
            "program": {
                "change_action": 0.1, 
                "change_instruction": 1.0, 
                "add_instruction": 0.5, 
                "swap_instructions": 1.0, 
                "remove_instruction": 0.5
            }, 
            "team": {
                "add_program": 0.7, 
                "mutate_program": 0.2, 
                "remove_program": 0.7
            }
        }, 
        "replacement_rate": {
            "points": 0.2, 
            "teams": 0.5
        }
    }, 
    
    "advanced_training_parameters": {
        "seed": 1, # use None for a random seed (obs.: it doesn"t guarantee that the same seeds lead to the same runs)
        "use_operations": [
            "+", "-", "*", "/", 
            "ln", "exp", "cos", 
            "if_lesser_than", 
            "if_equal_or_higher_than"
        ], 
        "extra_registers": 4, 
        "diversity": {
            "k": 10, 
            "metrics": [
                "genotype"
            ]
        }, 
        "novelty": {
            "enabled": false,
            "use_fitness": true
        },
        "use_weighted_probability_selection": false, # if False, uniform probability will be used
        "use_agressive_mutations": true, 
        "second_layer": {
            "path": "actions_reference/actions.json", 
            "enabled": false
        }
    },

    "debug": {
        "enabled": false,
        "output_path": "logs/"
    },

    "verbose": {
        "dont_show_std_deviation_in_reports": true
    }
}